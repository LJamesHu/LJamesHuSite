<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description></description>
    <link>http://localhost:4000/LJamesHuSite/</link>
    <atom:link href="http://localhost:4000/LJamesHuSite/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 09 Apr 2021 16:18:57 -0700</pubDate>
    <lastBuildDate>Fri, 09 Apr 2021 16:18:57 -0700</lastBuildDate>
    <generator>Jekyll v4.1.1</generator>
    
      <item>
        <title>Hello World Version 2: Electric Boogaloo</title>
        <description>&lt;p&gt;Hello World Version 2: Electric Boogaloo&lt;/p&gt;

&lt;p&gt;This is basically marking the relaunch of the site. Given that Wordpress site felt a little outdated in terms of design, structure, and my own ability to customize it, I decided to move towards a Jekyll solution hosted on Github Pages. Part test, part just fun project to revamp and possibly make a real blog that I can be proud of.&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Oct 2018 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/LJamesHuSite/technical/2018/10/01/hello-world-version-2-electric-boogaloo.html</link>
        <guid isPermaLink="true">http://localhost:4000/LJamesHuSite/technical/2018/10/01/hello-world-version-2-electric-boogaloo.html</guid>
        
        
        <category>technical</category>
        
      </item>
    
      <item>
        <title>Tax Rates Compared to Corruption</title>
        <description>&lt;p&gt;Reddit tends to be a highly liberal place, supporting the idea of higher taxes and more benefits as something good for society and the economy. While this is sometimes true it isn’t always. In particular, one person &lt;a href=&quot;https://np.reddit.com/r/bestof/comments/3p0or5/danish_doctor_drops_devastating_dissertation_on/cw2nuz7&quot;&gt;stated&lt;/a&gt; that Scandinavia’s high taxes and low corruption are indicative of a larger trend of high taxes correlating with less corruption. I wanted to explore this trend, especially since from my own knowledge, countries like Italy are renown for their incredibly high corruption, and certainly have higher taxes than the United States. While the sentiment seems nice, I couldn’t see this necessarily being true. Didn’t make enough sense so I did a simple investigation. The line drawn through is a linear regression but with very poor fit so it must be taken with a grain of salt.&lt;/p&gt;

&lt;p&gt;As you can see, the conclusion they drew is not necessarily true. It looks almost wholly random and inconsistent. The narrative posed sounds nice but really needs investigation before it can be stated as fact. I used CPI from &lt;a href=&quot;http://www.transparency.org/cpi2014/results/&quot;&gt;Transparency International&lt;/a&gt; and OECD Tax Wedge information from &lt;a href=&quot;http://www.keepeek.com/Digital-Asset-Management/oecd/taxation/taxing-wages-2015_tax_wages-2015-en#page20&quot;&gt;the OECD Taxing Wages paper&lt;/a&gt;. This was then compiled in Excel for a quick and dirty visualization.&lt;/p&gt;

&lt;p&gt;Afterwards I &lt;a href=&quot;https://np.reddit.com/r/dataisbeautiful/comments/3p5awo/tax_rates_vs_corruptions_perceptions_index_oc/&quot;&gt;posted it on reddit&lt;/a&gt;, which was somewhat received well by the DataIsBeautiful subreddit and gave me some valuable input on visualization design.&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Dec 2016 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/LJamesHuSite/technical/2016/12/01/tax-rates-compared-to-corruption.html</link>
        <guid isPermaLink="true">http://localhost:4000/LJamesHuSite/technical/2016/12/01/tax-rates-compared-to-corruption.html</guid>
        
        
        <category>technical</category>
        
      </item>
    
      <item>
        <title>Heart-icle</title>
        <description>&lt;p&gt;Heart-icle is a project to solve the problem of most summaries out there. There is so much news and articles out there to read and not enough time to actually read them. Summaries on sites right now are designed to specifically NOT give you the information you want, to entice you to click in order to actually get into the meat and bones.&lt;/p&gt;

&lt;p&gt;My proposal was to make a better, more intelligent summarizer. While there are some acceptable summarizers such as TextRank, which use a graph-based ranking model for text processing, somewhat analogous to Google’s PageRank, but for text. However it isn’t trained for it, just happens to leverage graphs intelligently to come up with semi-useful summary extractions, that may not be meaningful. I wanted to make a better summarizer.&lt;/p&gt;

&lt;p&gt;The core of this idea came from observing articles on the blogging site Medium. Users on the site can highlight parts of the article, and the most highlighted segment is the “Top Highlight”. The more I read articles on Medium, the more I felt that Medium highlights were actually quite representative of the article in one line. Given that I can scrape Medium articles, I can functionally have a labeled data set to train a model and use that to come up with a model specifically trained for summarization.&lt;/p&gt;

&lt;p&gt;To do this I had to scrape over thirty thousand articles, on both Medium to get the articles and the relevant highlights, and also the Atlantic, to build up a meaningful corpus of news and article language for analysis. This was done through a combination of Selenium Webdriver and BeautifulSoup, which worked well in terms of downloading and processing a large amount of web data and stripping it down to the core article information.&lt;/p&gt;

&lt;p&gt;To generate the summaries themselves, there were a couple of models that I was looking at, but I ended up zeroing in on Doc2Vec. It’s both cutting edge, but also a new application of the tool. The canonical example for Word2Vec is the relationship between King and Queen is the same as Man and Woman.&lt;/p&gt;

&lt;p&gt;I wanted to take this conceptual framework and apply it to articles and summaries. If I take an article and compare it to its summary, I should be able to figure out what the summarization relationship is and then utilize that to find the summary for un-summarized articles.&lt;/p&gt;

&lt;p&gt;The results were fairly interesting, with a decent accuracy rate at roughly 10%, good for a short project trying to answer a complex question, but ultimately not good enough to feel like you could comfortably use it to generate summaries, and thus relegated to Github.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/LJamesHu/Heart-icle&quot;&gt;Heart-icle Code on Github&lt;/a&gt;&lt;/p&gt;

&lt;object data=&quot;http://localhost:4000/LJamesHuSite/assets/files/Heart-icle.pdf&quot; width=&quot;100%&quot; height=&quot;600&quot; type=&quot;application/pdf&quot;&gt;&lt;/object&gt;

&lt;p&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/Heart-icle.pdf&quot;&gt;Link to Download PDF Presentation&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Aug 2016 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/LJamesHuSite/technical/python/2016/08/01/hearticle.html</link>
        <guid isPermaLink="true">http://localhost:4000/LJamesHuSite/technical/python/2016/08/01/hearticle.html</guid>
        
        
        <category>technical</category>
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>Yelp Data Project</title>
        <description>&lt;p&gt;For this group project, I mainly focused on data collection/scraping strategies and mass collection and storage of data, although I did help with the analysis portions and the overall writeup.&lt;/p&gt;

&lt;p&gt;This project was for a Practical Data Science class that was intended for MBA students but was fascinating across the board and one of my favorite classes during my time at New York University.&lt;/p&gt;

&lt;p&gt;This report shows the difficulties in the collection of the data, the analysis, and the visualization strategies we used for data. We found some interesting conclusions, one of which is that restaurants offering a sponsored deal typically perform poorly comparatively.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/LJamesHu/Yelp-Data-Scraper&quot;&gt;Data Scraping Code on Github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The code was written in Python and relied heavily on the BeautifulSoup library. Analysis and visualizations were done using matplotlib and Tableau.&lt;/p&gt;

&lt;object data=&quot;http://localhost:4000/LJamesHuSite/assets/files/YelpDataProject.pdf&quot; width=&quot;100%&quot; height=&quot;600&quot; type=&quot;application/pdf&quot;&gt;&lt;/object&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/YelpDataProject.pdf&quot;&gt;Link to Download PDF Report&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/yelpr_East_Village.csv&quot;&gt;Sample Data&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Jun 2015 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/LJamesHuSite/technical/python/2015/06/01/yelp-data-project.html</link>
        <guid isPermaLink="true">http://localhost:4000/LJamesHuSite/technical/python/2015/06/01/yelp-data-project.html</guid>
        
        
        <category>technical</category>
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>Dota 2 Hero Builds Project</title>
        <description>&lt;p&gt;The Dota 2 Hero Builds Project is a project my friend &lt;a href=&quot;https://twitter.com/tortedelini&quot;&gt;Michael Cohen&lt;/a&gt; started. I provide a lot of the technical support to his project so he can get it running smoothly. I host his site &lt;a href=&quot;http://tortedelini.com/&quot;&gt;Armchair Athleticism / Torte De Lini.com&lt;/a&gt; on my own VPS server on a WordPress installation. I have also provided significant data analysis assistance, being a big part of his &lt;a href=&quot;http://tortedelini.com/2018/12/10/5-years-350-million-2018-dota-builds-project-year-review/&quot;&gt;5 years, 350 million&lt;/a&gt;, &lt;a href=&quot;http://tortedelini.com/2018/02/10/4-years-275-million-2017-dota-builds-project-year-review/&quot;&gt;4 years, 275 million&lt;/a&gt;, &lt;a href=&quot;http://tortedelini.com/2016/11/17/3-years-170-million-dota-builds-project-year-review/&quot;&gt;3 years, 170 million&lt;/a&gt;, &lt;a href=&quot;http://tortedelini.com/2015/10/28/2-years-100-million-dota-builds-project-overview/&quot;&gt;2 years, 100 million&lt;/a&gt;, and &lt;a href=&quot;http://tortedelini.com/2014/11/17/1-year-40-million-dota-builds-project-overview/&quot;&gt;1 Year, 40 million&lt;/a&gt; subscriptions benchmark articles and analysis, assisting in the data visualization and writing.&lt;/p&gt;

&lt;p&gt;To assist in getting statistics for all of the over 100 guides, I created a data collection scraper and analyzer for near instant calculation and parsing of the data. Normally it would take up to an hour to manually calculate and pull data every 2 weeks, which was automated into a single script that collects all the data and outputs a csv for intake.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/LJamesHu/Dota2GuideInfoScraper&quot;&gt;Dota 2 Guide Info Scraper on GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The code was written in Python and relied heavily on the BeautifulSoup library to pull information from each of this guides. This was then all compiled into an exe file so Torte de Lini could quickly use it without any Python setup or additional files.&lt;/p&gt;

&lt;object data=&quot;http://localhost:4000/LJamesHuSite/assets/files/guideData-2015-11-14-02-18-12.pdf&quot; width=&quot;100%&quot; height=&quot;600&quot; type=&quot;application/pdf&quot;&gt;&lt;/object&gt;

&lt;p&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/guideData-2015-11-14-02-18-12.csv&quot;&gt;Link to Download Sample CSV Data&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In addition to that, since Torte De Lini has many guides, so it is rather annoying to get people to subscribe to, favorite, or rate his guides. I learned how to make bookmarklets and designed a bookmarklet that allowed people to like, favorite and subscribe to all of his guides in one button press. It was a rather interesting project since I was relatively unfamiliar with bookmarklets and had to figure out how to set it up to work correctly.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/LJamesHu/Dota2SubLikeFav&quot;&gt;Dota2SubLikeFav Bookmarklets on GitHub&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 01 May 2015 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/LJamesHuSite/technical/python/2015/05/01/dota-2-hero-builds-project.html</link>
        <guid isPermaLink="true">http://localhost:4000/LJamesHuSite/technical/python/2015/05/01/dota-2-hero-builds-project.html</guid>
        
        
        <category>technical</category>
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>NYU Projects</title>
        <description>&lt;p&gt;In my four years as an undergrad at New York University, I have taken a wide variety of classes that have given me broad business knowledge and skills. These are an overall set of worthwhile or interesting projects from my time at New York University that show analysis, research skills, writing skills, and proficiency across multiple business areas.&lt;/p&gt;

&lt;p&gt;Two projects stand out in particular as being analytical and very business focused.&lt;/p&gt;

&lt;h2 id=&quot;smuckers-case-study&quot;&gt;Smuckers Case Study&lt;/h2&gt;

&lt;p&gt;This was a two week case study for PriceWaterhouseCoopers Industry Analysis Consulting Case Competition. The goal was to outline the strategic challenges and opportunities of a selected Fortune 500 company and come up with a plan to move the company forward.&lt;/p&gt;

&lt;p&gt;Initially we were undecided and needed to identify key Fortune 500 companies that we thought had strong potential. To do this, we had to parse the list of Fortune 500 companies for potential opportunities. Unfortunately the Fortune 500 data was locked up in an inaccessible form, paginated, and difficult read, analyze, or sort any aspects of the company, even though the information was there. So one of the first things I did was organize the Fortune 500 into more manipulable CSV format to allow for better analysis than the current Fortune 500 site.&lt;/p&gt;

&lt;p&gt;To simplify this, I created a script in Python with the BeautifulSoup library to scrape all the data in the site, then put it into a csv format. This made the data accessible and manipulable for analysis.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/LJamesHu/Fortune500Scraper&quot;&gt;Fortune 500 Scraping Code on Github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/Fortune500Data.csv&quot;&gt;Download Scraped Fortune 500 Data&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For our company, we chose J.M. Smuckers and came up with a comprehensive and innovative plan to drive sales through Smuckers’ core values.&lt;/p&gt;

&lt;object data=&quot;http://localhost:4000/LJamesHuSite/assets/files/nyu/SmuckersCaseStudy.pdf&quot; width=&quot;100%&quot; height=&quot;600&quot; type=&quot;application/pdf&quot;&gt;&lt;/object&gt;

&lt;p&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/SmuckersCaseStudy.pptx&quot;&gt;Link to Download Powerpoint&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;sovereign-bank-risk-study&quot;&gt;Sovereign Bank Risk Study&lt;/h2&gt;

&lt;p&gt;This study was the final project for the class Risk Management in Financial Institutions.&lt;/p&gt;

&lt;p&gt;The interesting part about this was how it took many of the concepts that we learned in class and applied them in a real life scenario. After taking data from the FDIC website, we had to process and apply strategies and our knowledge to the data to obtain a reasonable analysis of the bank.&lt;/p&gt;

&lt;p&gt;The project required a thorough analysis covering various risk exposures such as liquidity and credit risk, capital adequacy measures, profitability, and risk management tools that were being used. These gave interesting insights into the bank and also were doubly interesting in how they revealed the rather jarring changes due to the financial crisis in 2008.&lt;/p&gt;

&lt;object data=&quot;http://localhost:4000/LJamesHuSite/assets/files/nyu/SovereignBankAnalysis.pdf&quot; width=&quot;100%&quot; height=&quot;600&quot; type=&quot;application/pdf&quot;&gt;&lt;/object&gt;

&lt;p&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/SovereignBankAnalysis.pdf&quot;&gt;Link to Download PDF Report&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;other-projects&quot;&gt;Other Projects&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/GlobalPerspectivesMexico.pdf&quot;&gt;Global Perspectives on Enterprise Systems – Mexico: Problems, Strengths and the Path&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/GlobalPerspectivesIndiaPresentation.pdf&quot;&gt;Global Perspectives on Enterprise Systems – India Presentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/GrupoDammAnalysis.pdf&quot;&gt;International Studies Program – Grupo Damm Analysis Presentation&lt;/a&gt;: A class presentation structured around learning about international business, featuring a one week trip to Barcelona to learn and study the culture.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/EconomicsOfPhilanthropy.pdf&quot;&gt;The Economics of Philanthropy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/EmergingMarketsPeru.pdf&quot;&gt;Topics in Emerging Financial Markets – Peru Presentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/Canon.pdf&quot;&gt;Canon Presentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/CanonCSR.pdf&quot;&gt;Canon Corporate Social Responsibility Presentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/CanonVSmartphones.pdf&quot;&gt;Canon and the Smartphone Threat&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/LJamesHuSite/assets/files/nyu/KindleFirePublishers.pdf&quot;&gt;Kindle Fire Presentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 01 Apr 2015 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/LJamesHuSite/technical/2015/04/01/nyu-projects.html</link>
        <guid isPermaLink="true">http://localhost:4000/LJamesHuSite/technical/2015/04/01/nyu-projects.html</guid>
        
        
        <category>technical</category>
        
      </item>
    
      <item>
        <title>Hello World</title>
        <description>&lt;p&gt;Hello World!&lt;/p&gt;

&lt;p&gt;This is just a test first post to make sure everything works!&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Jan 2015 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/LJamesHuSite/technical/2015/01/01/hello-world.html</link>
        <guid isPermaLink="true">http://localhost:4000/LJamesHuSite/technical/2015/01/01/hello-world.html</guid>
        
        
        <category>technical</category>
        
      </item>
    
  </channel>
</rss>
